---
title: CS231n 课程笔记
date: 2019-12-19 21:40:00
mathjax: true
footnote: true
---

这里记录我看 CS231n 课程的笔记内容，其实内容都比较基础，只是我的习惯是必须得写下来才能记得住，所以做了这个笔记，来涵盖整个课程的核心内容。我看的视频是 2017 年的版本：[https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk)

在记录课程内容的同时，我也会对课程的内容做重新整理，同时加入一些额外的信息和我的一些理解。另外，由于「形而上」的东西听得太多了，所以这里的笔记也不会记录那些内容。

这个课程主要面向的是「图像识别」(<i>Image Recognition</i>)，其中涉及的主要技术是卷积神经网络 (<i>Convolutional Neural Networks</i>, CNN)。

## 关于 Machine Learning

在这个课程中，我们主要是用神经卷积网络，也就是 Deep Learning 来解决图像识别的问题。图像识别实质上是一个**分类问题** (Classification)：事先我们定义一系列的类别，然后将输入图像划分为特定的类别。这可以视为一个特殊的函数，函数接收一个图片作为输入，输出一个离散的类别判断结果。这个问题是非常复杂的，我们无法显式地，或者说以解析的形式给出这样的函数。因此，解决这类问题，我们一般都是采用数据驱动的方法。所谓数据驱动，是指：

1. 收集足够数量的**带标注**的数据；
2. 使用**机器学习**训练出一个分类器 (Classifier)；
3. 在测试集上评估分类器的性能水平。

分类器是机器学习最早的引用。在介绍深度学习之前，我们先来从一些比较基础的机器学习方法开始了解机器的一些基本原理和设计思想。

### 数据集与数据建模

在图像分类问题中，输入数据为图像格式。在计算机中，图像本质上是一个多维矩阵。例如对于 RGB 三通道的图像，其数据表示为 $width \times height \times 3$。

对于机器学习来说，足够数量的标注数据及测试数据是非常重要的。在学习过程中，我们一般采用现有的公开数据集。例如这里我们就是用公开数据集 [CIFAR10](https://en.wikipedia.org/wiki/CIFAR-10)。这个数据集包括了 10 个类别的图像，对于每个类别，各有 50000 个训练图像和 10000 个测试图像。每个图像的大小是 $32 \times 32 \times 3$

![CIFAR10 数据集类别和图像示例](https://imgs.codewoody.com/uploads/big/1a23b6c81566c8da141925d0e1f36ed6.png)

### Nearest Neighbor

为了区分不同类别的图像，我们首先需要度量两个不同的图像之间的差别。这里我们介绍一些度量两个图像之间差别的方法。这里图像差别也称成为图像作为**向量**在高维空间中的**图像距离**

> 这里定义的图像距离，一般要求被比较的图像拥有相同的尺寸。如果图像尺寸不同可以通过缩放来变换到一致的尺寸后再计算距离。


L1 距离也被成为曼哈顿距离。L1 距离定义如下：

$$
d_1 (I_1, I_2) = \sum_{p} |I_1^p - I_2^p|
$$

这里的 $p$ 可以视为**逐像素**的迭代器。下面的例子有助于进一步理解 L1 距离的定义：

![L1 距离示例](https://imgs.codewoody.com/uploads/big/a1ef2bc8a5d4339ab38b530909ddd624.png)

> 这种逐像素的定义方法对于语义内容的鲁棒性是非常差的，例如如果图像的亮度发生变化，就会导致距离的大幅变化。

基于 L1 距离的定义，也可以实现一个简单的机器学习模型，Nearest Neighbor：

```python
import numpy as np

class NearestNeighbor:
    def __init__(self):
        pass

    def train(self, X, Y):
        # X 的尺寸是 N x D，每行是一个输入的训练样本，一共 N 个样本。Y 则是一维的。
        self.Xtr = x
        self.ytr = y  # 这里只是简单地记录下训练数据

    def predict(self, X):
        num_test = X.shape[0]
        Ypred = np.zeros(num_test, dtype=self.ytr.dtype)
        # 遍历每个训练样本，计算 L1 距离，按照距离最近的原则选出类别
        for i in xrange(num_test):
            distance = np.sum(np.abs(self.Xtr - X[i:]), axis=1)
            min_index = np.argmin(distance)
            Ypred[i] = self.ytr[min_index]
        return Ypred
```

> 且不论 L1 距离的效率。上面的机器学习模型中，训练过程的复杂度是 O(1)，在训练阶段只需要记住训练数据就可以了。但是预测过程的复杂度是 O(N)，因为需要逐个比对输入样本和训练集数据的距离。这对于模型的实际应用是非常不利的。对于机器学习应用来说，我们可以接收在训练过程中慢一点，但是不能接收在应用过程中太慢。

Nearest Neighbor (NN) 的分类效果如下图所示：

<img src="https://imgs.codewoody.com/uploads/big/92fc7b3dc9413d9d7f526fb2646060ab.png" alt="" style="width: 60%"/>

可以看到，NN 分类出来的结果，类别之间的切线非常曲折，这意味这少数的偏差值或者标注的错误会对分类结果产生比较大的影响，同时也不符合我们直观观察的结果，缺少真实世界的连续性。K-NN 算法就是为了解决这个问题而提出的。

### K-NN

K-NN 算法的思想是，比起在 NN 算法中我们值选择最近的 **1 个**点作为判决依据，在K-NN中，我们让距离输入点最近的 $K$ 个点进行**投票**，哪个类别的多，就判决为哪个类别。例如 $K = 3$ 时，距离输入点最近的 3 个样本点中，2 个是类别 A 的，1 个是类别 B 的，则输入点被判决为类别 A。K-NN 分类效果如下图：

![可以看到随着 K 的增长，不同区域之间的犬牙交错现象得到了抑制（红蓝之间的边界线）。白色区域为投票出现平票的区域。](https://imgs.codewoody.com/uploads/big/ebf2ba0f23b9150f4e3b47c546b7e1d6.png)

这里投票的过程没有加权重，在 K-NN 算法中，可以对投票环节进行不同的权重设计以达到不同的效果【~不过即便使用了 K-NN 算法的改进，这类基于距离的算法在图像的**语义层面**的分类上效果还是不好，所以基本上图像方面的问题都不实用 K-NN 算法。不过 K-NN 算法非常简单，适合让入门者了解机器学习的一些基本概念】。

### 更多不同类型的距离定义

上面的 K-NN 算法说明中我们一直使用的是 L1 距离。除了这种距离定义以外，还有其他众多不同的距离定义形式。如 L2 距离，又称欧几里得距离 (欧氏距离) 的定义为：

$$
d_2(I_1, I2) = \sqrt{\sum_p(I_1^p - I_2^p)^2}
$$

> 这里讨论一下 L1 和 L2 物理意义的区别。L1 距离的定义依赖于坐标轴，如果将坐标轴旋转一下，那么点之间的 L1 距离就会发生变化。L2 则不依赖于坐标轴的定义。因此 L2 适应用比较一般的情况，而如果坐标轴具备一定的特殊含义时，L1 距离可能会有比较好的效果。另外，计算量也可能成为需要考虑的因素。L2 的计算量要比 L1 大的多。
>
> 当然在实际应用中，还是靠尝试两者看效果来决定到底使用哪种。

### 超参数与 Validation

在使用 K-NN 算法时，如何选择参数 K 的值，如何选择距离函数是我们在训练开始以前就要指定的参数。这里需要我们设置，而不是从数据学习来的参数我们称之为超参数 (<i>Hyperparameter</i>)。如何设置合适的超参数的值依赖于具体的问题【~调参大法好】。

那么，如何调参呢？很多初学者会想当然地认为，调参的目的是让训练的模型在训练集上获得最好的性能，但是这是非常不好的做法。例如在 K-NN 算法中，设置 $K = 1$ 能够获得更好的精度。又例如在多项式曲线拟合中，如果有 100 个点，那么使用 100 阶的多项式去拟合能够在训练集上的完美的误差 -- 0。但是我们训练机器学习模型并不是为了让我们的模型在训练集上使用，而是在更多潜在的数据上使用。

那么一个简单改进思路是设置专门的测试集，在测试集上调试超参数的值。但是这也会产生上面提到的那种超参数和数据之前产生**过强**的耦合现象。更好的做法，是在训练集，测试集之外，设置专门的验证集 (<i>Validation</i>)，我们在验证集上调节超参数，最后在测试集上评估模型的性能【~使用这种做法，而不是使用前面两种错误的做法】。

更加强化的做法，我们称之为 <i>Cross-Validation</i>，即交叉验证。我们将训练数据分割为若干等分，然后逐个将某个等分作为验证集，将其他的作为训练集。**这种做法一般适合小规模的数据集，在深度学习中用的比较少**。

![图中绿色的为训练集，黄色的为验证集，红色的是测试集](https://imgs.codewoody.com/uploads/big/f2ed2d410c34321b7c4621bc8721823e.png)

## 线性分类

### 分类器的形式

线性分类 (Linear Classfication) 中，线性的意思代表了在这类分类器其中，分类器通过对特征数据进行线性组合来得到分类判决的依据。从可视化的角度来看，线性分类器中，不同类别的分界表现为高维的平面。特别的，在二维情况下，这个分界表现为直线，直线的两侧为不同的类别【~当然界面的线性会限制线性分类器的使用范围】。

> 线性分类是支撑向量机 (SVM) 的扩展。

例如在 CIFAR 10 分类问题中，使用线性分类意味着我们使用一个线性函数 $f(x, W)$ 将图像输入 $x$ 转化分类依据的分数。其中 $W$ 为需要从数据中学习的参数。

![](https://imgs.codewoody.com/uploads/big/78dd0d4698a9e829e8f25b613d918539.png)

这里线性函数的具体形式为: 

$$
f(x, W) = Wx + b
$$

> 如果给 $x$ 扩展一个列，且将新的维度设置为 1，则 $b$ 也可以整合进矩阵 $W$

这里矩阵 $W$ 为 $10 \times 3072$【~3072 = 32 \* 32 \* 3】。

![](https://imgs.codewoody.com/uploads/big/9fdd0fd146bb8a20de949cb19b00f58b.png)

<div id="meaning-of-w"></div>

如何理解线性分类器中的参数矩阵 $W$ 呢？事实上，参数矩阵基于模板创建了**模板图像**，然后通过模板图像来识别输入。我们将 $W$ 中的每一行还原成图像，结果如下：

![](https://imgs.codewoody.com/uploads/big/bfb6b365136e1d5872e684207d06ca2d.png)

我们可以从中看出对应类别的一些特征。这反应了参数矩阵 $W$ 作为**模板**图像的意义。在线性分类器中，受限于分类器的结构，每个类别我们只能生成一个这样的模板图像。而在更加复杂的模型中，我们可以得到层次更加丰富，数量更加庞大的模板模型。

> Assignment 1: [http://cs231n.github.io/assignments2017/assignment1/](http://cs231n.github.io/assignments2017/assignment1/)

### 损失函数

损失函数 (<i>Loss Function</i>) 是一个在机器学习与优化问题中非常重要的概念，它是效用函数 (<i>Utility Function</i>) 的反面。损失函数量化了预测结果的好坏程度。那么，找到让损失函数最小的参数，就能实现模型的最优化。损失函数的选择对于模型的性能有决定性的影响。

在本章节我们使用的线性函数中，损失函数的形式为：在给定数据集 $\{(x_i, y_i\}_{i = 1}^{N}$，其中 $x_i$ 为代表图像的向量数据，$y_i$ 为整型的标签值。损失函数的形式为 $L_i (f(x_i, W), y_i)$。这是单个样本的损失。模型在整个数据集上的平均损失为：

<div style="border: 1px solid">
$$
L = \frac{1}{N}\sum_i L_i (f(x_i, W), y_i)
$$
</div>

#### SVM Loss

源自支撑向量机的损失函数形式为：

$$
\begin{aligned}
L_i &= \sum_{j \neq y_i} \left\{ \begin{array}{ll}
0, & \text{if}\quad s_{y_i} \geq s_j + 1\\
s_j - s_{y_i} + 1, & \text{otherwise}
\end{array}
\right.\\
&= \sum_{j \neq y_i} \max (0, s_j - s_{y_i} + 1)
\end{aligned}
$$

其原理为逐一检查分类器为每个类别给出的分数。对于非正确的某个类别，如果分类器给出的分数低于为正确的分类给出的分数（这里设置了一个判决的阈值，阈值为1，即分数值需要低于超过1，反过来就是正确的类别的分数要有至少 1 的分数优势），则贡献 0 的损失。反之，贡献的损失值为分数差加上阈值 1。最后将所有非正确类别贡献的损失加起来。显然，如果分类器给出的结果是正确的，且有足够的辨识度（不给两个类别十分相近的评分），则损失是0。否则总会有一个正的损失分数，即分数的取值范围是$[0, \infty)$。

> 这里的阈值选择其实是比较随意的。1 是上面的损失函数定义中的唯一常数。事实上我们并不关心分数的绝对大小，而是关注其相对大小。例如如果将 $W$ 和 $b$ 同时乘以 10，那么分数之间的差也会乘以 10，那么阈值也可以变为 10。因此这里阈值常数只不过大致限定了分数的数量级，其选择不会对分类器的性能产生根本性的影响。因此这里我们设置成 1 就可以了。这个阈值不是需要优化的超参数。

下面用一个例子来说明。如果对于一张猫的照片，给出三个类别 cat, car, frog 的分数分别为 3.2, 5.1, -1.7，则损失计算的方法是：

$$
\begin{aligned}
L_i &= \sum_{j \neq y_i} \max(0, s_j, s_{y_i} + 1) \\
&= \max(0, 5.1 - 3.2 + 1) + \max(0, -1.7 - 3.2 + 1) \\
&= 2.9 + 0 \\
&= 2.9
\end{aligned}
$$

SVM Loss 的代码实现示例为：

```python
def L_i_vectorized(x, y, W):
    scores = W.dot(x)
    margins = np.maximum(0, scores - scores[y] + 1)
    margins[y] = 0
    loss_i = np.sum(margins)
    return loss_i
```

#### Softmax

我们并不关心分类器给出的分数的绝对大小，而是关心分数的相对大小。因此我们需要一种方法能够对分数输出的值进行形式上的统一。另外，有时候我们需要给出一个结果判断的概率评估。基于这两个需求，我们可以使用 Softmax (cross-entropy loss) 来处理分数结果。Softmax函数的形式为：

$$
P(Y = k | X = x_i) = \frac{e^{s_k}}{\sum_j e^{s_j}}
$$

此时对应的损失函数可以定义为：

$$
L_i = - \log P(Y = y_i | X = x_i) = -\log \left(\frac{e^{y_i}}{\sum_j e^{s_j}}\right)
$$

> Softmax 损失函数相比于 SVM 损失函数的一个特点在于，SVM 损失只关心分数是否存在一定的优势，而只要优势存在，具体的分差他就不再关心。例如分数 [10, 9, 9] 和 分数 [10, -100, -100] (第一个类别是正确的类别) 产生的损失是一样的。但是 Softmax 进一步关心分差的值的大小。因此，Softmax 要求不断地向正确的选项上集中分数。

### 过拟合与正则化

在上面的「超参数与Validation」章节我们提到了模型与训练数据**过度*耦合的问题。例如考虑一个曲线拟合问题，如果曲线形式足够复杂，让曲线穿过每一个数据点，那么可以取得最小的误差。

<img src="https://imgs.codewoody.com/uploads/big/58ed0392663a305e925f7e3c2f7cd399.png" alt="" style="width: 60%"/>

但是在潜在的应用数据上，这种拟合曲线性能不一定好：

<img src="https://imgs.codewoody.com/uploads/big/a05532ae8094411124878313ca6c6fb9.png" alt="" style="width: 60%"/>

使用一些更加简单的模型能够取得更好的效果：

<img src="https://imgs.codewoody.com/uploads/big/90bc6494411295a632f44f6b374adce6.png" alt="" style="width: 60%"/>

这种模型过于拟合训练数据的情况我们称之为过拟合。为了解决过拟合问题，我们为损失函数引入了**正则化**项目 (<i>Regulation</i>)。改进后的损失函数的形式是：

$$
L(W) = \frac{1}{N}\sum_{i = 1}^{N}L_i (f(x_i, W), y_i) + \lambda R(W)
$$

正则化可以避免模型过于复杂，保持比较简洁的模型。这是因为简单的模型可能有更大的普适性。正则化的目的也可以说是为了**泛化**模型的适用范围。

这里的 $\lambda$ 为超参数。

> 为什么加入正则化项可以阻止模型过于复杂呢？是因为函数 $R(\cdot)$ 评估了模型的复杂度？

比较常用的正则化项如下：

- L1 正则化：$R(W) = \sum_k \sum_l W^2_{k,l}$
- L2 正则化：$R(W) = \sum_k \sum_l |W_{k,l}|$
- Elastic net (L1 + L2): $R(W) = \sum_k \sum_l \beta W^2_{k,l} + \sum_k \sum_l |W_{k,l}|$

> Dropout, Batch Normalization, Stochastic Depth 也是正则化的手段

### 优化

在我们已经定义分类器的形式，也就是分数的定义方式 $f(x, W) = W x$，并且引入了损失函数的定义之后，寻找合适的参数矩阵 $W$ 的过程，其实就是最小化损失函数的过程。这是一个优化问题 (<i>Optimization</i>)。

### 梯度下降

梯度的概念是「多元函数」的斜率概念。而梯度定义为函数向各个变量求导得到的导数组成的向量。**梯度向量的反向即为函数值下降速度最快的方向**。这个概念在高等函数里面是比较基础的概念。剩下的问题是，如何求解损失函数的梯度 $dL/dW$。

> 用数值方法计算梯度是非常糟糕的算法。因为在深度学习中，参数的数量非常庞大，逐个维度计算数值导数计算量非常大。但是数值方法可以用来验证我们的梯度解析公式是否正确。

> 梯度只是指明了下降的方向，参数应该沿着负梯度方向前进多少的距离，这是一个需要提前指定的超参数。这个参数一般称之为 <i>Learning Rate</i>。

#### 随机梯度下降

损失函数的完整形式为

$$
L(W)=\frac{1}{N} \sum_{i=1}^{N} L_{i}\left(x_{i}, y_{i}, W\right)+\lambda R(W)
$$

其中要遍历整个训练集，在数据量比较大时，这意味着极为庞大的计算量。随机梯度下降 (<i>Stochastic Gradient Descent</i>) 则解决了这个问题。在计算梯度时，我们不再是遍历整个训练集，而是从训练集中随机选出一个子集（一般是32/64/128 个），然后基于这个子集计算梯度。

#### 梯度的计算 (Computational Graphs)

我们使用 <i>Computational Graphs</i> 的方法来处理复杂的模型的梯度计算问题。例如，前面提到的线性分类器，其计算图为：

![](https://imgs.codewoody.com/uploads/big/12e2d7f35082a8eb86e47c1baf6eceb1.jpg)

在计算图的基础上，我们可以逆着计算流的方向，使用 [<i>back propagation</i>](https://en.wikipedia.org/wiki/Backpropagation) 的方法来计算梯度，其原理是微分计算的[链式法则](https://zh.wikipedia.org/zh-hans/%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99)。下面是一个简单的使用 <i>back propagation</i> 计算梯度的例子:

![](https://imgs.codewoody.com/uploads/big/d346be5dafd0027f469da0b7c02d5a99.png)

> 当然要是你微积分和矩阵论学的足够好，可以直接算。

<blockquote>

Sigmoid 函数 $\sigma (x) = \frac{1}{1 + e^{-x}}$ 的微分是

$$
\frac{d \sigma (x)}{d x} = (1 - \sigma (x)) \sigma (x)
$$

</blockquote>

## 神经网络

神经网络 (<i>Neural Networks</i>)。

### 神经网络模型

在上一个章节，我们建立起了一个线性分类的模型框架，这个框架包括线性模型，损失函数，以及优化方法 (梯度下降)。其中，线性模型的形式是 $f = Wx$。我们将其扩展为 $f = W_2 \max (0, W_1 x)$，这就成为一个**两层**的神经网络模型。

> 两层模型中的 $\max(0, \cdot)$ 计算实际上就是 Relu 函数，这类函数成为激励函数 (<i>activation functions</i>)，后面我们会提到。这类**非线性**函数是神经网络多层叠加的关键。缺乏这些非线性函数作为中继，将线性函数组装起来其实仍然是一层的。

<img src="https://imgs.codewoody.com/uploads/big/06b383e0ac612356327bbd24f88f7e74.png" alt="" style="width: 60%"/>

这个扩展过程可以继续扩展下去，这样我们可以得到更深层数的神经网络的模型。例如三层的结构：$f=W_3 \max (0, W_2 \max (0, W_1 x))$

在[前面](#meaning-of-w)我们提到过，线性分类器具有作为**模板图像**的含义。但是，线性分类器只能为每一个类别的图像创建一个模板。在多层神经网络中，网络结构的复杂性使得模型可以为同一类别创建**不同层次**的多个模板。

> 注意，尽管这个模型的名字叫做神经网络，但是这只是**类比**而已，神经网络模型和生物学意义上的神经网络有本质的不同。神经网络模型也不是仿生学。

### 激励函数

从某种程度上，激励函数可以视为将神经网络的不同层链接在一起的胶水，也是神经网络中**非线性要素**的来源。下面是一些常用的激励函数。

![](https://imgs.codewoody.com/uploads/big/ef67b15e4df2bdc02a28c9f31ea88978.png)

### 隐藏层

隐藏层 (<i>hidden layer</i>) 是对多层神经网络中除输入输出层以外的其他层的称呼。

![](https://imgs.codewoody.com/uploads/big/30469a05fd796b2d3819cd60329ac053.png)

## 卷积神经网络